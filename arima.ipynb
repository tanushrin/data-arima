{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple ARIMA Model for Non-Seasonal Time-Series Forecast\n",
    "\n",
    "Our goal in this challenge is to apply the basic concepts of time series analysis to one-dimension data\n",
    "\n",
    "In this challenge, we'll go through the following steps : \n",
    "1. load and visualize the data;\n",
    "2. train our models and make predictions;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Load Data\n",
    "Let's start by loading the Time Series of the challenge. Run the line below to download the dataset as a CSV file, then load the CSV in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/09-Time-Series/www_usage.csv > data/www_usage.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data/www_usage.csv', names=['value'], header=0)\n",
    "y = df.value\n",
    "\n",
    "df.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This abstract time series does not seem seasonal, but with some increasing trend and somehow \"sticky\" (i.e. with some auto-regressivity). So it may be a good candidate for Auto-Regressive Moving Average (ARIMA) models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build ARIMA Model\n",
    "We will try to forecast the data thanks to ARIMA models (Auto Regressive Integrated Moving Average).\n",
    "\n",
    "For that, we will need to :\n",
    "1. find how to stationarize the time series (I in SARIMA)\n",
    "2. find the auto-regressive (AR) part\n",
    "3. find the moving average (MA) part\n",
    "4. Fit\n",
    "5. Assess performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Ensure Stationarity\n",
    "\n",
    "ARIMA models apply to \"stationary\" time series only.\n",
    "\n",
    "üëâ Check its stationarity precisely using the [`Augmented Dick Fuller test`](https://www.statsmodels.org/stable/generated/statsmodels.tsa.stattools.adfuller.html), and especially its p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value should be less than 0.05 to have a 95% confidence in the stationarity.  \n",
    "If the p-value is larger than 0.05, we cannot reject the null hypothesis (null hypothesis = \"the process is not stationary\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the time series is not stationary, it needs to be stationarized through **differencing**. \n",
    "- It means that we take the difference between each value and the preceding one (*first difference*).\n",
    "- Repeat the process on the differentiated series if you want the *second difference*, etc...\n",
    "\n",
    "üëâ Find the minimum order of differencing we need to make it stationary (plot the curves to visualize them, and print their adfuller p-value to be sure)\n",
    "\n",
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "\n",
    "`pd.Series.diff`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a close call here between one and two diff orders. Differentiating time series too much may also reduce the performance of your ARIMA models. Let's have a closer look:\n",
    "\n",
    "üëâ Plot autocorrelation plot ([`plot_acf`](https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html)) for diff order 1 and 2.\n",
    "\n",
    "(üí°Pro tip: Avoid duplicating statsmodels plots by calling `plt.show()` or by adding `;` to the end of each instantiation of a statsmodels plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our \"second order diff\" autocorrelation plot, the lag coefficient n¬∞1 is close to 0, while the second one escapes far into negative territory. This might indicate we have over-differentiated the series. (Remember: we never care about the lag n¬∞0 which is always equal to 1)\n",
    "\n",
    "üëâ Let's (tentatively) keep only one diff order and name this series `y_diff` (we can always try more diff later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "challenfigy"
    ]
   },
   "outputs": [],
   "source": [
    "y_diff = y.diff().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just found the term \"I\" in ARIMA: `d = 1` for 1-diff before stationary (\"I\" refers to \"integration\", \"d\" for differentiation...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Select AR order (p) and MA order (q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MA($\\color{blue}{q}$) = number of lag beyond which the $\\color{blue}{ACF}$ of  $Y^{\\color{green}{(d)}}$ cuts off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MA order (`q`) can be found by looking at the autocorrelation plot ([`plot_acf`](https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html)) applied to`y_diff`. \n",
    "\n",
    "üëâ determine `q`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum value we should consider for fitting our model seems to be q = 4. However, if we were to use Auto-ARIMA (more on this later) we would find that using q=2 yields ideal results so to begin with, let's try setting q=2. \n",
    "\n",
    "When in doubt, go with the simpler model that sufficiently explains the Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AR($\\color{red}{p}$) = number of lags beyond which the $\\color{red}{PACF}$ of $Y^{\\color{green}{(d)}}$  cuts off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AR order (`p`) can be found by investigating the **p**artial autocorrelation plot [`plot_pacf`](https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_pacf.html) applied to `y_diff`.\n",
    "\n",
    "(Partial autocorrelation can be imagined as the correlation between the series and its lag, after excluding the contributions from the intermediate lags. So, PACF sort of conveys the pure correlation between a lag and the series)\n",
    "\n",
    "üëâ Determine `p`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could choose `p = 3` as the first 3 lag terms seem above the significance level, but we could also go with a simpler model `p = 1`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Build the model\n",
    "\n",
    "Now that you have chosen the values for `p`, ` d`, and `q` for the ARIMA, \n",
    "\n",
    "üëâ build the `arima_model` from `statsmodels`.\n",
    "- fit the model\n",
    "- print the model (`.summary`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è If your p-values are too high, try to remove these terms by reducing the corresponding AR or SA coefficients.\n",
    "\n",
    "You can evaluate the overall performance of your fit by minimizing the [`AIC - Akaike Information Criterion`](https://towardsdatascience.com/the-akaike-information-criterion-c20c8fd832f2) value\n",
    "\n",
    "It seems that the (1,1,1) ARIMA models have less chance of overfitting (p-values remain low) and maintain a quasi-similar AIC score than other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Visualize your model predictions with the `plot_predict()` method\n",
    "\n",
    "- Look closely at the method default params, especially `dynamic` ones. \n",
    "- Do you think your model would have such a good performance in reality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è `dynamic=False` makes use of all available values `y` to predict `y_pred`, making your ARIMA prediction use up to $y_{t-1}$ to predict $y_t$. In reality, you don't have access to all `y`, especially if you want to predict several intervals in the future.\n",
    "\n",
    "üëâ Try to use `dynamic=True` to plot a prediction of the _last 15 values_ in a situation where the model only has _access to data up to 85_. That is to say, the model:\n",
    "- predicts 86 based on true [1...85]\n",
    "- then predicts 87 based on [1...85] _plus_ its previously predicted value for 86\n",
    "- etc...iteratively until 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è That's still not a _true_ forecast! Why?\n",
    "\n",
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "Our model has \"seen\" the whole `y_true` series during the fitting phase!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Out-of-Sample Forecasts (real \"future\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Create a train-test-split keep the last 15 data points only for the test set, and train your ARIMA on the train set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ We are \"now\" in step 85 and have never seen the future:\n",
    "- Use the `get_forecast()` method on your fitted `arima` model to \"forecast\" the 15 next data points (i.e beyond the end of your train dataset) \n",
    "\n",
    "The method returns a `PredictionResultsWrapper` object from `statsmodels`.\n",
    "\n",
    "**üíª Store this result in a variable named `forecast_results`.**  \n",
    "\n",
    "It is hard to navigate at first, but here are some tips:\n",
    "- You can find your forecasts in `forecast_results.predicted_mean`\n",
    "- Your confidence intervals are given by `forecast_results.conf_int()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Plot forecasted values as well as the higher and lower range of 95% uncertainty interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Try to also plot your previous 85 `y` real data points to better grasp model performance relative to the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Can you trust your 95% confidence interval? (conditions for inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Plot the residuals `model.resid` to ensure there are no patterns\n",
    "- Normally distributed\n",
    "- Mean zero\n",
    "- Uniform variance\n",
    "- No autoregressive patterns (you can plot_acf the residuals anyway if you want)\n",
    "\n",
    "Note: residuals are constructed by 'seeing' all data as in `plot_predict(dynamic=False)`\n",
    "\n",
    "Also, try to plot a histogram or KDE fit of the residuals to see if they are approximately normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Cross-validated performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Below are the given the most common performance metrics for time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "def forecast_accuracy(y_pred: pd.Series, y_true: pd.Series) -> float:\n",
    "    \n",
    "    mape = np.mean(np.abs(y_pred - y_true)/np.abs(y_true))  # Mean Absolute Percentage Error\n",
    "    me = np.mean(y_pred - y_true)             # ME\n",
    "    mae = np.mean(np.abs(y_pred - y_true))    # MAE\n",
    "    mpe = np.mean((y_pred - y_true)/y_true)   # MPE\n",
    "    rmse = np.mean((y_pred - y_true)**2)**.5  # RMSE\n",
    "    corr = np.corrcoef(y_pred, y_true)[0,1]   # Correlation between the Actual and the Forecast\n",
    "    mins = np.amin(np.hstack([y_pred.values.reshape(-1,1), y_true.values.reshape(-1,1)]), axis=1)\n",
    "    maxs = np.amax(np.hstack([y_pred.values.reshape(-1,1), y_true.values.reshape(-1,1)]), axis=1)\n",
    "    minmax = 1 - np.mean(mins/maxs)             # minmax\n",
    "    acf1 = acf(y_pred-y_true, fft=False)[1]                      # Lag 1 Autocorrelation of Error\n",
    "\n",
    "    forecast = ({\n",
    "        'mape':mape,\n",
    "        'me':me,\n",
    "        'mae': mae,\n",
    "        'mpe': mpe,\n",
    "        'rmse':rmse,\n",
    "        'acf1':acf1,\n",
    "        'corr':corr,\n",
    "        'minmax':minmax\n",
    "    })\n",
    "\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Play with your ARIMA hyper-parameters and see the impact on your forecast performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to run a Grid Search for (p,d,q) using `pmdarima`. Use at least\n",
    "- `test='adf'`\n",
    "- `trace=True`\n",
    "- `error_action='ignore'`\n",
    "- `suppress_warnings=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "\n",
    "model = pm.auto_arima(\n",
    "    y_train, \n",
    "    start_p=0, max_p=3,\n",
    "    start_q=0, max_q=3, \n",
    "    d=None,           # let model determine 'd'\n",
    "    test='adf',       # using adf test to find optimal 'd'\n",
    "    trace=True, error_action='ignore',  suppress_warnings=True\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Cross-validate the Performance of your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, results and Grid Search should always be cross-validated: \n",
    "\n",
    "Feel free to use [`sklearn.TimeSeriesSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) to create contiguous K-folds to truly evaluate the performance of your model and find the best hyperparams after cross-validation.\n",
    "\n",
    "<img src='https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_013.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ARIMA - Cross-Validation using TimeSeriesSplit + Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('AIC').groupby('(p, d, q)').mean()['AIC'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Our initial choice of model (1, 1, 2) is not so bad!\n",
    "Notice that the dataset (100 data points) is in reality way too small to cross-validate anything!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
